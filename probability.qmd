---
title: "Probability"
format: html
editor: visual
---

# Rules of Probability

Probabilities are defined for events. An event is some outcome that we could potentially or hypothetically observe or experience, such as the result of rolling a fair six-sided die. In mathematical notation, we often write an event as a capital letter, for example A. If A is the event of rolling a die and getting a "4", this event has probability 1/6 and we write that as $P(A) = \frac{1}{6}$ We might want to represent the numerical result of the die roll as the random variable X and then we write $P(X=4)=\frac{1}{6}$

Probabilities must be between zero and one for any event A because if we add up the probabilities of all possible events, those probabilities must add to one. For the die rolling example: $$
\sum^6_{i=1}P(X=i)=1
$$ The complement of an event $A^C$ means that the event does not happen. Since probabilities must add to one, $P(A^C)=1-P(A)$

If A and B are two events, the probability that A or B happens (this is an inclusive or, meaning that either A or B or both happen) is the probability of the union of the events: $$
P(A\cup B) = P(A)+P(B)-P(A \cap B)
$$ Where $\cup$ represents union "or" and $\cap$ represents intersection "and" . If a set of events $A_i$ for $i=1,\dots,m$ are mutually exclusive (only one can happen), then $$
P(\bigcup^m_{i=m}A_i)=\sum^m_{i=1}P(A_i)
$$ \## Odds Probabilities can be re-expressed in terms of odds. Suppose again that we denote rolling a "4" on a fair six-sided die as the event A. Then P(A) = 1/6 The odds for event A, denoted $\mathcal{O}(A)$ is defined as $$\mathcal{O}(A) = \frac{P(A)} {P (A ^ c)} = \frac{P(A)}{(1 - P(A))}$$ Hence, in this example: $$
\mathcal{O}(A) = \frac{1/6} {5/6} = \frac{1}{5}
$$ This can also be expressed as 1:5 or as 5:1 "odds against". Thus, an event with probability 3/10 has 3/7 odds (7:3 "odds against") and an event with probability 4/5 has 4:1 odds.

We can also calculate probabilities from odds. If an event B has a:b odds, (with a\>0 and b\>0) then $$\frac{P(B)}{(1-P(B))} = \frac{a}{b} \rightarrow P(B)\times b = a-P(B)\times a \rightarrow P(B)= \frac{a}{a+b}$$ Thus, an event with 2:5 odds has probability 2/7

## Expectation

The expected value of a random variable ( X ) is described as a weighted average of the values that ( X ) can take, with weights given by the probabilities of those values.

The formula for the expected value is given as:

$$
E(X) = \sum_{i=1}^{n} x_i \cdot P(X = x_i)
$$

An example is provided for the expected value of a fair six-sided die:

$$
E(X) = \sum_{i=1}^{6} i \cdot P(X = i) = \sum_{i=1}^{6} i \cdot \frac{1}{6} = \frac{1}{6} (1 + 2 + 3 + 4 + 5 + 6) = 3.5
$$ Note that the die cannot achieve this value, but if you were to roll the die many times and average the values, the result would likely be close to 3.5

While the die cannot achieve this value in a single roll, rolling the die many times and averaging the values would likely result in a value close to 3.5.

# Bayesian vs frequentist probability

In statistics, *frequentist probability* interprets probability as the long-run frequency of an event in repeated trials, while "Bayesian probability" interprets probability as a degree of belief about an event, incorporating prior knowledge and updating that belief as new data is collected; essentially, frequentist probability focuses on the data itself, while Bayesian probability focuses on the probability of a hypothesis given the data, allowing for the inclusion of prior information.

*Frequentist*: Probability is the limit of the relative frequency of an event in an infinite number of repetitions of an experiment. *Bayesian*: Actively incorporates prior beliefs about parameters through a "prior distribution" which is updated with new data to form a "posterior distribution".

**Hypothesis testing**

*Frequentist*: Uses p-values to test hypotheses based on the likelihood of observing data as extreme or more extreme than what was observed, assuming the null hypothesis is true.

*Bayesian*: Calculates the probability of a hypothesis given the observed data, directly assigning probabilities to hypotheses.

# Framework of Bayesian probability

We can quantify probabilities by thinking about what is a fair bet. So for example, we want to ask what's the probability it rains tomorrow? Then we can ask about a bet that you might be willing to take if you think it's fair. Suppose you'd be willing to take the bet that if it rains tomorrow, you win 4\$ and if it doesn't, you lose 1\$, you can think of this as odds 4:1. This is equivalent to the other direction of the bet: if it rains you lose 4\$ and if it doesn't, you win 1\$. We can see this is fair by looking at the expected return. You are defining a probability of rain $P(rain)=\frac 1 5$

We can see that these two bets are equivalent looking at your expected return:

$P(rain)=\frac 1 5$ $P(no\ rain)=\frac 4 5$

We can check if the numbers in this bet are fair by checking that the expected return in case of the two events occurring is 0:

Bet 1: return if it rains: $4 \frac 1 5 = 0.8$ Return if it doesn't rain $1 \frac 4 5 = 0.8$

Bet 2: return if it rains: $1 \frac 4 5 = 0.8$ Return if it doesn't rain $4 \frac 1 5 = 0.8$

::: exercise-box
Consider this game:

you flip a fair coin. If the result is 'heads' you win 3\$, if the result is 'tails' you lose 4\$. What is your expected return?

3(1/2)-4(1/2) = -0.5
:::

::: exercise-box
Chess bet

Your friend offers a bet that she can beat you in a game of chess. If you win, she owes you \$5, but if she wins, you owe her \$3

Odds: 5:3 P(win)= 5/8

She is 100% confident that she will beat you. What is her expected return for this game? P(win) = 3\*(1/1) - 5 (0) = 3

Suppose she is only 50% confident that she will beat you (her personal probability of winning is p=0.5. What is her expected return now? P(win) = 3\*(1/2) - 5 (1/2) = -1

Now assuming your friend will only agree to fair bets (expected return of \$0), find her personal probability that she will win. Report your answer as a simplified fraction.

To find your friend's personal probability of winning the game of chess under the condition of a fair bet (expected return of \$0), we set up the equation using the concept of expected value.

Let's denote: -$p$ as the probability that your friend will win the game. - $1 - p$ as the probability that you will win the game.

The expected return for a fair bet should be 0. Therefore, we set up the expected value equation as follows: $5 \times (1 - p) - 3 \times p = 0$ Now, let's solve for ( p ):

$5 - 5p - 3p = 0$ $5 - 8p = 0$ $-8p = -5$ $p = \frac{5}{8}$

Therefore, the probability that your friend will win is $\frac{5}{8}$.

This means your friend believes she has a ( \frac{5}{8} ) chance of winning the game to agree to this fair bet.

Her expected return: 3(5/8)-5(3/8)
:::

::: exercise-box
Weather bet

Suppose your friend offers a pair of bets:

- if it rains or is overcast tomorrow, you pay him 4\$, otherwise he pays you 6\$ - if it sunny you pay him 5\$, otherwise he pays you 5\$

Suppose rain, overcast and sunny are the only events in consideration. If you make both bets simultaneously, this is called a *Dutch book* as you are guaranteed to win money. How much do you win regardless of the outcome?

-   if it rains or overcast: -4+5 =1
-   if it is sunny: 6-5 =1

Apparently your friend doesn't understand the laws of probability. Let's examine the bets he offered.

For bet (i) to be fair, his probability that it rains or is overcast must be .6 (you can verify this by calculating his expected return and setting it equal to \$0):

4p-6(1-p) = 0\
4p-6+6p =0

10p -6 =0

10p= 6

p = 6/10 =0.6

For bet (ii) to be fair, his probability that it will be sunny must be .5:

5p-5(1-p) = 0

5p-5+5p =0

10p =5

p = 5/10 =0.5

This results in a "Dutch book" because your friend's probabilities are not coherent. They do not add up to 1. What do they add up to? 0.6+0.5=1.1
:::

Bayesian probability adjust the probabilities based on updated information, let's see this with an example:

::: exercise-box
Estimating the Size of Atacama

The country of Chile is divided administratively into 15 regions. The size of the country is 756,096 square kilometers. How big do you think the region of Atacama is? Let's define the following events:

-   (A_1): The event that Atacama is less than 10,000 square kilometers.

-   (A_2): The event that Atacama is between 10,000 and 50,000 square kilometers.

-   (A_3): The event that Atacama is between 50,000 and 100,000 quare kilometers.

-   (A_4): The event that Atacama is more than 100,000 square kilometers.

We initially assign probabilities to these events based on the average size of Chile's regions (756096/15 = 50406):

-   (A_1): P((A_1)) = 5%

-   (A_2): P((A_2)) = 45%

-   (A_3): P((A_3)) = 45%

-   (A_4): P((A_4)) = 5%

Given that Atacama is the fourth largest region:

-   (A_1): P((A_1)) = 1%

-   (A_2): P((A_2)) = 14%

-   (A_3): P((A_3)) = 60%

-   (A_4): P((A_4)) = 25%

Given that the smallest region (Santiago Metropolitan) has an area of 15,403 square kilometers:

-   (A_1): P((A_1)) = 0%

-   (A_2): P((A_2)) = 15%

-   (A_3): P((A_3)) = 60%

-   (A_4): P((A_4)) = 25%

Given that the third largest region, Aysén del General Carlos Ibáñez del Campo, has an area of 108,494 square kilometers:

-   (A_1): P((A_1)) = 0%

-   (A_2): P((A_2)) = 10%

-   (A_3): P((A_3)) = 65%

-   (A_4): P((A_4)) = 25%
:::

# Conditional probability

In conditional probability we ask what is the probability of event `A` happening, given that event `B` happened. $P(A|B)$ (read *Probability of A given B*)

$P(A|B)$ is the probability of event `A` occurring, given that event `B` has already occurred. This means you are only considering the subset of cases where B happens and then looking how often A also happens in those cases. 

$$
P(A|B) = \frac{P(A \cap B)}{P(B)}
$$
**Join Probability** $P(A \cap B)$ is the probability that both events `A` and `B` occur simultaneously. This is considering the likelihood of both events happening at the same time without any additional conditions 
$$
P(A \cap B) = P(B) \times P(A \mid B)
$$
Let's get a better understanding of the concepts with an example

::: exercise-box 
Understanding Conditional and Joint Probability

Let's consider a deck of 52 cards to understand the difference between conditional probability and joint probability.

*Definitions*

- $P(A \mid B)$: The probability of event $A$ occurring given that event $B$ has already occurred.
- $P(A \cap B)$: The probability that both events $A$ and $B$ occur simultaneously.

We want to find the probability of drawing a red card (event $A$) given that the card is a heart (event $B$).

*Event A*:  **Probability of Drawing a Red Card ($P(A)$):**
   $$
   P(A) = \frac{\text{Number of red cards}}{\text{Total number of cards}} = \frac{26}{52} = \frac{1}{2}
   $$

*Event B*:  **Probability of Drawing a Heart ($P(B)$):**
   $$
   P(B) = \frac{\text{Number of hearts}}{\text{Total number of cards}} = \frac{13}{52} = \frac{1}{4}
   $$

*Join Probability*: **Probability of Drawing a Red Card and a Heart ($P(A \cap B)$):**
   Since all hearts are red, the probability of drawing a red card and a heart is the same as the probability of drawing a heart:
   $$
   P(A \cap B) = P(B) = \frac{13}{52} = \frac{1}{4}
   $$

*Conditional Probability* **Probability of Drawing a Red Card Given that the Card is a Heart ($P(A \mid B)$):**
Using Bayes' Theorem:
   $$
   P(A \mid B) = \frac{P(A \cap B)}{P(B)} = \frac{\frac{13}{52}}{\frac{13}{52}} = 1
   $$
*Conclusion*:

- $P(A \mid B)$: The probability of drawing a red card given that the card is a heart is 1.
- $P(A \cap B)$: The probability of drawing a red card and a heart is $\frac{1}{4}$.

This example demonstrates how conditional probability considers the subset of cases where event $B$ has occurred, while joint probability considers the likelihood of both events happening together within the entire sample space. 

:::
# Bayes Theorem:

The general formula for conditional probability is:
$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)} \\
\text{ and  } \\
P(B \mid A) = \frac{P(B \cap A)}{P(A)}
$${#eq-ConditionalProbability}

This formula tells us how to find the probability of event $A$ occurring given that event $B$ has already occurred by dividing the joint probability $P(A \cap B)$ by the probability of $B$.

Bayes' Theorem is a specific application of conditional probability and is stated as:

$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B \mid A) P(A) + P(B \mid A^C) P(A^C)}=  \frac{P(B \mid A) \cdot P(A)}{P(B)} = \frac{P(A\cap B)}{P(B)}
$${#eq-BayesTheorem}

In this case, $A$ and $B$ are specific events, and we are using the conditional probability of $B$ given $A$ to find the conditional probability of $A$ given $B$.

WE are now just going to see how each term relates to each other to get to the equation above:

We can use the conditional probability formula to find $P(B \mid A)$ and apply it in the Bayes probability theorem.


$$
P(A \mid B) = \frac{\frac{P(B \cap A)}{P(A)} \cdot P(A)}{P(B)} \rightarrow \frac{{P(B \cap A)} }{P(B)}
$$

and
$$
P(A \cap B) =  P(A \mid B) \cdot P(B) \\ \text{ and  } \\ 
P(B \cap A) =  P(B \mid A) \cdot P(A)
$$

Using Bayes' Theorem again, we have:
$$
P(A \mid B) = \frac{P(B \mid A) \cdot P(A)}{P(B)}
$$


let's practice this: 

:::exercise-box
Bayesian Probability Exercise

We have a total of 30 students: 

 - 9 are females. 
 - 12 are computer science majors.
 - 4 of the computer science students are females.

We want to determine the probability that a student is female given that they are a computer science major.

Let: 

 - $F$ be the event that a student is female. 
 - $CS$ be the event that a student is a computer science major.

We are looking for $P(F \mid CS)$, the probability that a student is female given that they are a computer science major.

*Applying Bayes' Theorem:*

Bayes' Theorem states:
$$
P(F \mid CS) = \frac{P(CS \mid F) \cdot P(F)}{P(CS)}
$$

1. **Calculate $P(F)$:**

$$
P(F) = \frac{\text{Number of females}}{\text{Total number of students}} = \frac{9}{30}
$$

2. **Calculate $P(CS)$:**

$$
P(CS) = \frac{\text{Number of computer science majors}}{\text{Total number of students}} = \frac{12}{30}
$$

3. **Calculate $P(CS \mid F)$:**

$$
P(CS \mid F) = \frac{\text{Number of female computer science students}}{\text{Total number of females}} = \frac{4}{9}
$$

4. **Apply Bayes' Theorem:**

$$
P(F \mid CS) = \frac{P(CS \mid F) \cdot P(F)}{P(CS)} = \frac{\left(\frac{4}{9}\right) \cdot \left(\frac{9}{30}\right)}{\left(\frac{12}{30}\right)}
$$


$$
P(F \mid CS) = \frac{\frac{4}{30}}{\frac{12}{30}} = \frac{4}{12} = \frac{1}{3}
$$

So, the probability that a student is female given that they are a computer science major is $\frac{1}{3}$.

*Calculate the probability that a Student is a Female Given that She is Not a Computer Science Major ($CS^C$):*

1. **Calculate $P(CS^C)$:**

$$
P(CS^C) = \frac{\text{Number of non-Computer Science majors}}{\text{Total number of students}} = \frac{18}{30}
$$

2. **Calculate $P(CS^C \cap F)$:**

$$
P(CS^C \cap F) = \frac{\text{Number of females who are not Computer Science majors}}{\text{Total number of students}} = \frac{5}{30}
$$

3. **Calculate $P(F \mid CS^C)$:**

$$
P(F \mid CS^C) = \frac{P(CS^C \cap F)}{P(CS^C)} = \frac{\frac{5}{30}}{\frac{18}{30}} = \frac{5}{18}
$$

So, the probability that a student is female given that they are not a computer science major is $\frac{5}{18}$.

*Conclusion*

The probability that a student is female given that they are a computer science major is $\frac{1}{3}$. The probability that a student is female given that they are not a computer science major is $\frac{5}{18}$.


Notice that the probability of being a female student and studying computer science is not the same as the probability of studying computer science and being a female:

$P(CS \mid F) = 4/9 \neq P(F \mid CS)= 1/3$

:::

Let's see this in another example

:::exercise-box
Lab Test 

The probability of a test being positive given that the person has HIV is .977
The probability of a test being negative given that they don't have the virus is .926

We calculated that the probability of a USA citizen having HIV is .0026

So if we randomly select someone from this population and tested them with this test, what is the probability that they actually have HIV given that they tested positive?

- $P(T^+ \mid H) = 0.977$
- $P(T^- \mid H^C) = 0.926$
- $P(H) = 0.0026$

Bayes' Theorem:**
$$
P(H \mid T^+) = \frac{P(T^+ \mid H) \cdot P(H)}{P(T^+)}
$$

**Probability of testing positive**
The probability of testing positive is the probability of testing positive given that they have HIV plus the probability of testing positive given that they don't have HIV

$$
P(T^+) = P(T^+ \mid H) \cdot P(H) + P(T^+ \mid H^C) \cdot P(H^C)
$$
a. **Calculate the probability of not having HIV:**
$$
P(H^C) = 1 - P(H) = 1 - 0.0026 = 0.9974
$$
b. **Calculate the probability of testing positive given not having HIV:**
$$
P(T^+ \mid H^C) = 1 - P(T^- \mid H^C) = 1 - 0.926 = 0.074
$$

$$
P(T^+) = (0.977 \cdot 0.0026) + (0.074 \cdot 0.9974) \rightarrow 0.0025402 + 0.0738076 = 0.0763478
$$
**Substitute the values in Bayes Theorem:**
$$
P(H \mid T^+) = \frac{0.977 \cdot 0.0026}{0.0763478} \rightarrow \frac{0.0025402}{0.0763478} \approx 0.0333
$$
Therefore, the probability that a person has HIV given that they tested positive is approximately 0.0333.
:::


## Indepence of the events
If the two events A and B are independent from each other, then the probability of A given B is just the probability of A. In that case the probability of the two together is $P(A\cap B) = P(A)P(B)$

Taking this to the example we just see, we can see that the probability of being a female given that they are a computer science student is not equal to the probability of being a female, which means that these two events are not independent. 


# Bayes' Theorem with Multiple Outcomes

When there are more than two possible outcomes, Bayes' Theorem expands to handle the multiple outcomes. For example, when there are three possible outcomes $A_1$, $A_2$, and $A_3$, such that exactly one of these must happen, Bayes' Theorem is as follows:

## Partition of the Space

If the events $A_1, A_2, \ldots, A_m$ form a partition of the space (exactly one of the $A_i$'s must occur, i.e., the $A_i$'s are mutually exclusive and:
$$
\sum_{i=1}^{m} P(A_i) = 1
$$

Then, Bayes' Theorem can be written as:
$$
P(A_j \mid B) = \frac{P(B \mid A_j) \cdot P(A_j)}{\sum_{i=1}^{m} P(B \mid A_i) \cdot P(A_i)}
$$

## Continuous Distributions

For continuous distributions, the sum in Bayes' Theorem is replaced with an integral. We will explore this in the next lesson.




